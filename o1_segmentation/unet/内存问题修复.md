# 内存问题修复 - DataLoader Worker被Kill

## 🐛 问题诊断

**错误**: `DataLoader worker (pid 430084) is killed by signal: Killed`

这是**系统内存（RAM）不足**，不是GPU内存问题。

### 原因分析

1. **batch_size=16** + **patch_size=(192,192,96)** 导致每个batch占用大量RAM
2. **num_workers=6**，每个worker都在加载数据，占用大量RAM
3. **prefetch_factor=2** 也增加了内存占用
4. 系统RAM可能不足（需要检查系统内存）

## ✅ 已实施的修复

### 1. 减少DataLoader Workers
- **num_workers**: 6 → **2**
- **效果**: 减少并行加载的worker数量，降低RAM占用

### 2. 减少Prefetch
- **prefetch_factor**: 2 → **1**
- **效果**: 减少预取batch数量，降低RAM占用

## 🔧 如果问题仍然存在

如果还是出现worker被kill，可以尝试以下方案（按优先级）：

### 方案1: 稍微降低batch_size（推荐）
```python
# 在 train.py 中
batch_size=1 if args.debug else 12  # 从16降到12
```
- **效果**: 减少每个batch的RAM占用
- **速度影响**: 略微降低（但仍比原来的4快很多）

### 方案2: 稍微降低patch_size
```python
# 在 data_loader.py 中
patch_size=(160, 160, 80)  # 从(192,192,96)降低
```
- **效果**: 减少每个patch的RAM占用
- **速度影响**: 较小

### 方案3: 进一步减少num_workers
```python
# 在 data_loader.py 中
num_workers=1  # 从2降到1
```
- **效果**: 进一步减少RAM占用
- **速度影响**: 数据加载可能变慢

### 方案4: 组合优化（如果前3个都不行）
```python
batch_size=10
patch_size=(160, 160, 80)
num_workers=1
```

## 📊 内存占用估算

### 当前配置（batch_size=16, patch_size=(192,192,96)）
- **每个patch**: ~192×192×96×4 bytes ≈ 14MB
- **每个batch**: 16×14MB ≈ 224MB（仅数据）
- **每个worker**: 可能还需要额外的内存用于数据加载和增强
- **总估算**: 可能需要2-4GB RAM（取决于数据增强复杂度）

### 优化后（num_workers=2, prefetch_factor=1）
- **Worker内存**: 2×2-4GB ≈ 4-8GB
- **主进程**: ~1-2GB
- **总需求**: ~5-10GB RAM

## 💡 建议

1. **先尝试当前修复**（num_workers=2, prefetch_factor=1）
2. **如果还是被kill**，按顺序尝试：
   - batch_size=12
   - patch_size=(160,160,80)
   - num_workers=1
3. **检查系统内存**：
   ```bash
   free -h  # 查看可用内存
   ```
   确保有足够的可用内存（建议至少16GB）

## 🎯 预期效果

修复后应该可以正常运行，速度仍然会显著提升：
- **batch_size=16**: 比原来的4快约4倍
- **即使降到12**: 仍然比原来的4快约3倍

## ⚠️ 注意事项

- GPU内存（48GB）充足，问题在系统RAM
- 如果系统RAM不足，可能需要：
  - 关闭其他占用内存的程序
  - 或降低batch_size/patch_size
  - 或增加系统RAM

